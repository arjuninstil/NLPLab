{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing vectorized code in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ and $B$ be the matrices representing points in $d$ dimensional space, each having $m$ and $n$ points (rows) respectively, i.e., $A$ is $m \\times d$ and $B$ is $n \\times d$.\n",
    "\n",
    "Let the task be to calculate the Euclidean distance for each point from $A$ to each point in $B$, the result is $m \\times $n matrix $C$, where $C_{i, j}$ represents distance between $i^{th}$ point of $A$ and $j^{th}$ point of $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dimensions\n",
    "D = 500\n",
    "M = 700\n",
    "N = 1000\n",
    "\n",
    "# matrices\n",
    "A = np.random.rand(M, D)\n",
    "B = np.random.rand(N, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive implementation of this task will be going for each point in $A$ and for each point in $B$ and calculating the corresponding euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_naive(A, B):\n",
    "    \"\"\"Compute Euclidean distance from each point in A to each point in B.\n",
    "    Args: \n",
    "        A: `numpy.ndarray` MxD dimensional array.\n",
    "        B: `numpy.ndarray` NxD dimensional.\n",
    "    \n",
    "    Returns:\n",
    "        C: `numpy.ndarray` distances matrix.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Incompatible matrix dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if A.shape[1] != B.shape[1]:\n",
    "        raise ValueError('Incompatible dimensions of matrices!')\n",
    "    \n",
    "    C = np.empty((A.shape[0], B.shape[0]))\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(B.shape[0]):\n",
    "            C[i, j] = np.sqrt(np.sum(np.square(A[i] - B[j])))\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write function for measuring execution time of any given function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_exec_time(f, name='This function', *args):\n",
    "    \"\"\"Print execution time for the given function.\n",
    "    Args:\n",
    "        f: function to execute.\n",
    "        name: `string` name of the function or any comment.\n",
    "        *args: arguments to pass to function.\n",
    "    \n",
    "    Returns:\n",
    "        Return value of function.\n",
    "    \"\"\"\n",
    "    \n",
    "    import time\n",
    "    tic = time.time()\n",
    "    ret = f(*args)\n",
    "    toc = time.time()\n",
    "    print(\"%s took %f seconds.\"%(name, toc-tic))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive implementation took 4.768615 seconds.\n"
     ]
    }
   ],
   "source": [
    "C1 = print_exec_time(distances_naive, 'Naive implementation', A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to accomplish the same task with different approach. Instead of explicitly performing Python `for` loops we will use basic Linear Algebra and NumPy Broadcasting. There is a very good tutorial on NumPy Broadcasting by <a href=\"https://eli.thegreenplace.net/2015/broadcasting-arrays-in-numpy/\">Eli Bendersky.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_vectorized(A, B):\n",
    "    \"\"\"Compute Euclidean distance from each point in A to each point in B.\n",
    "    \n",
    "    Args: \n",
    "        A: `numpy.ndarray` MxD dimensional array.\n",
    "        B: `numpy.ndarray` NxD dimensional.\n",
    "    Returns:\n",
    "        C: `numpy.ndarray` distances matrix\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Incompatible matrix dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if A.shape[1] != B.shape[1]:\n",
    "        raise ValueError('Incompatible dimensions of matrices!')\n",
    "        \n",
    "    # (A - B)^2 = A^2 - 2AB + B^2\n",
    "    A_sqr = np.sum(np.square(A), axis=1).reshape(A.shape[0], -1)\n",
    "    B_sqr = np.sum(np.square(B), axis=1)\n",
    "    C = np.sqrt(A_sqr - 2*A.dot(B.T) + B_sqr)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized implementation took 0.100518 seconds.\n"
     ]
    }
   ],
   "source": [
    "C2 = print_exec_time(distances_vectorized, 'Vectorized implementation', A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see vectorized implementation significantly outperforms naive implementation. The main reason for this is that in vectorization `for` loops are performed internally by NumPy in fast C code instead of slow Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further in details of vectorized implementation, let's check whether naive implementation agrees with vectorized implementation. For checking this we will use Frobenius norm of the difference matrix $C1$ and $C2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_matrices(A, B, eps=0.001):\n",
    "    \"\"\"Compare whether two matrices are identical.\n",
    "    \n",
    "    Args: \n",
    "        A: `numpy.ndarray` MxD dimensional array.\n",
    "        B: `numpy.ndarray` NxD dimensional.\n",
    "    \n",
    "    Returns: `boolean`\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Incompatible matrix dimensions.\n",
    "    \"\"\"\n",
    "    if A.shape[1] != B.shape[1]:\n",
    "        raise ValueError('Incompatible dimensions of matrices!')\n",
    "        \n",
    "    diff = np.linalg.norm(A - B, ord='fro')\n",
    "    print(\"Difference: %f\" % diff)\n",
    "    return diff < eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_matrices(C1, C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 3 lines of code in vectorized implementation. But we will go through the details step by step, clarifying every aspect of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A = \\begin{bmatrix} \n",
    "    a_{11} & a_{12} & a_{13} & \\dots & a_{1d} \\\\\n",
    "    a_{21} & a_{22} & a_{23} & \\dots & a_{2d} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    a_{m1} & a_{m2} & a_{m3} & \\dots & a_{md}\n",
    "\\end{bmatrix}$, \n",
    "$B = \\begin{bmatrix} \n",
    "    b_{11} & b_{12} & b_{13} & \\dots & b_{1d} \\\\\n",
    "    b_{21} & b_{22} & b_{23} & \\dots & b_{2d} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    b_{n1} & b_{n2} & b_{n3} & \\dots & b_{nd}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "What we really want at the end is matrix $C = \\begin{bmatrix} \n",
    "    c_{11} & c_{12} & c_{13} & \\dots & c_{1n} \\\\\n",
    "    c_{21} & c_{22} & c_{23} & \\dots & c_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    c_{m1} & c_{m2} & c_{m3} & \\dots & c_{mn}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Where $c_{ij} = \\sqrt{(a_{i1} - b_{j1})^2 + (a_{i2} - b_{j2})^2 + \\dots + (a_{id} - b_{jd})^2}$ Euclidean distance between point (row) $i$ in $A$ and point (row) $j$ in $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding the expression under the square root gives the following:\n",
    "\n",
    "$(a_{i1} - b_{j1})^2 + (a_{i2} - b_{j2})^2 + \\dots + (a_{id} - b_{jd})^2 = \n",
    "a_{i1}^2 + \\dots + a_{id}^2 + b_{j1}^2 + \\dots + b_{jd}^2 - 2(a_{i1}b_{j1} + \\dots + a_{id}b_{jd})$\n",
    "\n",
    "The **crucial observation** here is that sum $a_{i1}^2 + \\dots + a_{id}^2$ appears in every column of row $i$ of $C$, while sum $b_{j1}^2 + \\dots + b_{jd}^2$ appears in every row of column $j$ of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum $a_{i1}^2 + \\dots + a_{id}^2$ is just summing the square of each entry in $i^{th}$ row of matrix $A$. This is exactly what code snippet in vectorized implementation `A_sqr = np.sum(np.square(A), axis=1).reshape(A.shape[0], -1)` does for all rows in $A$. More concretely, `A_sqr` will be NumPy array of shape $(m, 1)$ where each element of `A_sqr[m, i]` is sum of squares of entries in $i^{th}$ row of $A$.  Here, we reshape `A_sqr`, because we want it in every column of $C$.\n",
    "\n",
    "Similar argument is true for $b_{j1}^2 + \\dots + b_{jd}^2$ and line `B_sqr = np.sum(np.square(B), axis=1)` does the same for all rows in B. Notice, that we do not reshape this, because we want it in every row of $C$.\n",
    "\n",
    "The sum $(a_{i1}b_{j1} + \\dots + a_{id}b_{jd})$ can be written as $ab^{T}$, where $a$ and $b$ are treated as **row vectors**. For all rows in $A$ and for all rows in $B$ this can be written as $AB^{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line `C = np.sqrt(A_sqr - 2*A.dot(B.T) + B_sqr)` gives the final result, but do not forget to take the square root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
